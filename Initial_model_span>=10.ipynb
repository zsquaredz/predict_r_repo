{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "\n",
    "# Your code goes here\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, recall_score, precision_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21820, 22)\n",
      "(5993, 22)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = pd.read_csv('test_1.csv',delimiter = ',')\n",
    "data_neg = dataset1.loc[(dataset1['class']==0) & (dataset1['proj_span']>=10.0)]\n",
    "data_pos = dataset1.loc[(dataset1['class']==1) & (dataset1['proj_span']>=10.0)]\n",
    "print(data_neg.shape)\n",
    "print(data_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('test.csv',delimiter = ',')\n",
    "dataset1 = pd.read_csv('test_1.csv',delimiter = ',') # this one does not take care the CRAN before GH date\n",
    "dataset = dataset.loc[dataset['proj_span'] >= 10.0]\n",
    "dataset1 = dataset1.loc[dataset1['proj_span'] >= 10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27813, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = (dataset.drop('class', axis=1)).drop('id', axis=1)\n",
    "y = dataset['class']\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27813, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = (dataset1.drop('class', axis=1)).drop('id', axis=1)\n",
    "y_1 = dataset1['class']\n",
    "dataset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_intensity</th>\n",
       "      <th>class</th>\n",
       "      <th>final_teamsize</th>\n",
       "      <th>first_quater_teamsize</th>\n",
       "      <th>normalized_proj_span</th>\n",
       "      <th>num_CommitComment</th>\n",
       "      <th>num_Create</th>\n",
       "      <th>num_Delete</th>\n",
       "      <th>num_Fork</th>\n",
       "      <th>num_Gollum</th>\n",
       "      <th>...</th>\n",
       "      <th>num_Issues</th>\n",
       "      <th>num_Member</th>\n",
       "      <th>num_Public</th>\n",
       "      <th>num_PullRequest</th>\n",
       "      <th>num_PullRequestReviewComment</th>\n",
       "      <th>num_Push</th>\n",
       "      <th>num_Release</th>\n",
       "      <th>num_TeamAdd</th>\n",
       "      <th>num_Watch</th>\n",
       "      <th>proj_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.338187</td>\n",
       "      <td>0.215475</td>\n",
       "      <td>4.635099</td>\n",
       "      <td>4.554381</td>\n",
       "      <td>0.102066</td>\n",
       "      <td>0.100385</td>\n",
       "      <td>0.808794</td>\n",
       "      <td>0.488441</td>\n",
       "      <td>2.238917</td>\n",
       "      <td>0.389350</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090605</td>\n",
       "      <td>0.074246</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>5.193579</td>\n",
       "      <td>1.025564</td>\n",
       "      <td>14.056197</td>\n",
       "      <td>0.052745</td>\n",
       "      <td>0.007982</td>\n",
       "      <td>0.829936</td>\n",
       "      <td>186.270845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.765379</td>\n",
       "      <td>0.411159</td>\n",
       "      <td>237.525007</td>\n",
       "      <td>237.526338</td>\n",
       "      <td>0.140559</td>\n",
       "      <td>1.271779</td>\n",
       "      <td>2.544591</td>\n",
       "      <td>3.373186</td>\n",
       "      <td>230.851355</td>\n",
       "      <td>6.798492</td>\n",
       "      <td>...</td>\n",
       "      <td>9.073136</td>\n",
       "      <td>0.490074</td>\n",
       "      <td>0.178863</td>\n",
       "      <td>39.217515</td>\n",
       "      <td>22.574237</td>\n",
       "      <td>52.149186</td>\n",
       "      <td>0.655811</td>\n",
       "      <td>0.100736</td>\n",
       "      <td>8.089224</td>\n",
       "      <td>256.520035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.043831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.126761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.335347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.129863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>267.739130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39519.000000</td>\n",
       "      <td>39519.000000</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>38469.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4139.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>6158.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       activity_intensity         class  final_teamsize  \\\n",
       "count        27813.000000  27813.000000    27813.000000   \n",
       "mean             0.338187      0.215475        4.635099   \n",
       "std              1.765379      0.411159      237.525007   \n",
       "min              0.001468      0.000000        1.000000   \n",
       "25%              0.043831      0.000000        1.000000   \n",
       "50%              0.126761      0.000000        1.000000   \n",
       "75%              0.335347      0.000000        2.000000   \n",
       "max            267.739130      1.000000    39519.000000   \n",
       "\n",
       "       first_quater_teamsize  normalized_proj_span  num_CommitComment  \\\n",
       "count           27813.000000          27813.000000       27813.000000   \n",
       "mean                4.554381              0.102066           0.100385   \n",
       "std               237.526338              0.140559           1.271779   \n",
       "min                 0.000000              0.005479           0.000000   \n",
       "25%                 1.000000              0.015342           0.000000   \n",
       "50%                 1.000000              0.046027           0.000000   \n",
       "75%                 2.000000              0.129863           0.000000   \n",
       "max             39519.000000              0.986301          89.000000   \n",
       "\n",
       "         num_Create    num_Delete      num_Fork    num_Gollum      ...       \\\n",
       "count  27813.000000  27813.000000  27813.000000  27813.000000      ...        \n",
       "mean       0.808794      0.488441      2.238917      0.389350      ...        \n",
       "std        2.544591      3.373186    230.851355      6.798492      ...        \n",
       "min        0.000000      0.000000      0.000000      0.000000      ...        \n",
       "25%        0.000000      0.000000      0.000000      0.000000      ...        \n",
       "50%        0.000000      0.000000      0.000000      0.000000      ...        \n",
       "75%        1.000000      0.000000      0.000000      0.000000      ...        \n",
       "max      117.000000    114.000000  38469.000000    649.000000      ...        \n",
       "\n",
       "         num_Issues    num_Member    num_Public  num_PullRequest  \\\n",
       "count  27813.000000  27813.000000  27813.000000     27813.000000   \n",
       "mean       1.090605      0.074246      0.020099         5.193579   \n",
       "std        9.073136      0.490074      0.178863        39.217515   \n",
       "min        0.000000      0.000000      0.000000         0.000000   \n",
       "25%        0.000000      0.000000      0.000000         0.000000   \n",
       "50%        0.000000      0.000000      0.000000         0.000000   \n",
       "75%        0.000000      0.000000      0.000000         2.000000   \n",
       "max      401.000000     34.000000     13.000000      4139.000000   \n",
       "\n",
       "       num_PullRequestReviewComment      num_Push   num_Release   num_TeamAdd  \\\n",
       "count                  27813.000000  27813.000000  27813.000000  27813.000000   \n",
       "mean                       1.025564     14.056197      0.052745      0.007982   \n",
       "std                       22.574237     52.149186      0.655811      0.100736   \n",
       "min                        0.000000      0.000000      0.000000      0.000000   \n",
       "25%                        0.000000      1.000000      0.000000      0.000000   \n",
       "50%                        0.000000      4.000000      0.000000      0.000000   \n",
       "75%                        0.000000     13.000000      0.000000      0.000000   \n",
       "max                     2625.000000   6158.000000     54.000000      3.000000   \n",
       "\n",
       "          num_Watch     proj_span  \n",
       "count  27813.000000  27813.000000  \n",
       "mean       0.829936    186.270845  \n",
       "std        8.089224    256.520035  \n",
       "min        0.000000     10.000000  \n",
       "25%        0.000000     28.000000  \n",
       "50%        0.000000     84.000000  \n",
       "75%        0.000000    237.000000  \n",
       "max      607.000000   1800.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.3, random_state=20190101)\n",
    "X_tr_1, X_test_1, y_tr_1, y_test_1 = train_test_split(X_1, y_1, test_size=0.3, random_state=20190101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "ax1 = sns.countplot(x='class', data=dataset)\n",
    "ax1.set_xticklabels(['not Success', 'Success'])\n",
    "plt.title('Dataset with CRAN before GH')\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "sns.countplot(x='class', data=dataset1)\n",
    "ax2.set_xticklabels(['not Success', 'Success'])\n",
    "plt.title('Dataset don\\'t care CRAN before GH')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of the LogisticRegression classifier on training set: 0.93318\n",
      "Precision on train: 0.34911\n",
      "Recall on train: 0.04720\n",
      "\n",
      "Classification accuracy of the LogisticRegression classifier on test set: 0.92749\n",
      "Precision on test: 0.37037\n",
      "Recall on test: 0.05137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7709,   51],\n",
       "       [ 554,   30]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_tr, y_tr)\n",
    "ca = lr.score(X_tr, y_tr)\n",
    "print('Classification accuracy of the LogisticRegression classifier on training set: {:.5f}'.format(ca))\n",
    "y_pred = lr.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "ca = lr.score(X_test, y_test)\n",
    "y_pred = lr.predict(X_test)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test, pos_label=1)\n",
    "print('\\nClassification accuracy of the LogisticRegression classifier on test set: {:.5f}'.format(ca))\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))\n",
    "confusion_matrix(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.67942709e-01 -3.08858079e-01  8.34245840e-02  6.37150001e-07\n",
      "   6.18498294e-02  2.71538473e-01 -5.14369324e-01  2.23403723e-01\n",
      "  -1.05526435e-01 -2.09146639e-02  8.80533658e-02 -7.31509205e-02\n",
      "  -4.03973231e-02  1.47951362e-02  4.21030900e-03 -2.45371893e-03\n",
      "   1.34290646e-01 -4.76566975e-03  2.27280429e-01  1.16279875e-03]]\n",
      "[-2.64553923]\n"
     ]
    }
   ],
   "source": [
    "# display coef for logistic regression model\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of the LogisticRegression classifier on training set: 0.80780\n",
      "Precision on train: 0.70473\n",
      "Recall on train: 0.14913\n",
      "\n",
      "Classification accuracy of the LogisticRegression classifier on test set: 0.79422\n",
      "Precision on test: 0.74387\n",
      "Recall on test: 0.14399\n"
     ]
    }
   ],
   "source": [
    "# on dataset_1\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_tr_1, y_tr_1)\n",
    "ca = lr.score(X_tr_1, y_tr_1)\n",
    "print('Classification accuracy of the LogisticRegression classifier on training set: {:.5f}'.format(ca))\n",
    "y_pred = lr.predict(X_tr_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr_1, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "ca = lr.score(X_test_1, y_test_1)\n",
    "y_pred = lr.predict(X_test_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test_1, pos_label=1)\n",
    "print('\\nClassification accuracy of the LogisticRegression classifier on test set: {:.5f}'.format(ca))\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.29828601e-01 -1.35283178e-01  1.55324332e-01  7.46390222e-07\n",
      "  -3.98118848e-02  2.15372850e-01  2.61118097e-01 -6.79750539e-02\n",
      "  -2.48658206e-02  1.65496596e-02  1.40991179e-02 -8.12253788e-02\n",
      "  -5.50726350e-02 -4.36994443e-03  8.92615773e-03 -1.88510684e-02\n",
      "  -1.25162221e-02 -1.12801594e-02 -1.66178445e-02  1.36216215e-03]]\n",
      "[-1.51448536]\n"
     ]
    }
   ],
   "source": [
    "# display coef for logistic regression model\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test_1)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_tr)\n",
    "X_tr = ss.transform(X_tr)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "ss1 = StandardScaler()\n",
    "ss1.fit(X_tr_1)\n",
    "X_tr_1 = ss.transform(X_tr_1)\n",
    "X_test_1 = ss.transform(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of the LogisticRegression classifier on training set: 0.93497\n",
      "Precision on train: 0.42308\n",
      "Recall on train: 0.03520\n",
      "\n",
      "Classification accuracy of the LogisticRegression classifier on test set: 0.92893\n",
      "Precision on test: 0.41176\n",
      "Recall on test: 0.03596\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_tr, y_tr)\n",
    "ca = lr.score(X_tr, y_tr)\n",
    "print('Classification accuracy of the LogisticRegression classifier on training set: {:.5f}'.format(ca))\n",
    "y_pred = lr.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "ca = lr.score(X_test, y_test)\n",
    "y_pred = lr.predict(X_test)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test, pos_label=1)\n",
    "print('\\nClassification accuracy of the LogisticRegression classifier on test set: {:.5f}'.format(ca))\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00450831 -0.18776833  0.45993861  0.21014321  0.00788932  0.51336713\n",
      "  -0.813601   -0.48636341 -0.09522193 -0.03986958  0.17408188 -0.03486568\n",
      "  -0.03000811  0.0594795   0.02925375 -0.0597464  -0.07815385 -0.02439169\n",
      "  -0.03126276  0.21014321]]\n",
      "[-2.93340217]\n"
     ]
    }
   ],
   "source": [
    "# display coef for logistic regression model\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of the LogisticRegression classifier on training set: 0.80775\n",
      "Precision on train: 0.68632\n",
      "Recall on train: 0.15914\n",
      "\n",
      "Classification accuracy of the LogisticRegression classifier on test set: 0.79518\n",
      "Precision on test: 0.72861\n",
      "Recall on test: 0.15717\n"
     ]
    }
   ],
   "source": [
    "# on dataset_1\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_tr_1, y_tr_1)\n",
    "ca = lr.score(X_tr_1, y_tr_1)\n",
    "print('Classification accuracy of the LogisticRegression classifier on training set: {:.5f}'.format(ca))\n",
    "y_pred = lr.predict(X_tr_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr_1, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "ca = lr.score(X_test_1, y_test_1)\n",
    "y_pred = lr.predict(X_test_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test_1, pos_label=1)\n",
    "print('\\nClassification accuracy of the LogisticRegression classifier on test set: {:.5f}'.format(ca))\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.55114486 -1.22486499  1.74677539  0.18740666 -0.0922864   0.7049485\n",
      "   0.84166146 -1.63641074 -0.09491037  0.38657012  0.08689872 -0.1371789\n",
      "  -0.1921194  -0.00214079  0.04262487 -0.60193888 -0.20505716 -0.07103995\n",
      "  -0.04467461  0.18740666]]\n",
      "[-1.51324741]\n"
     ]
    }
   ],
   "source": [
    "# display coef for logistic regression model\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test_1)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training dataset: 0.9950177204787097\n",
      "Precision on train: 0.99570\n",
      "Recall on train: 0.92640\n",
      "\n",
      "Accuracy score on the test dataset: 0.93013\n",
      "Precision on test: 0.50265\n",
      "Recall on test: 0.16267\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_tr, y_tr)\n",
    "y_pred = rf.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "accuracy_score_train = rf.score(X_tr, y_tr)\n",
    "print('Accuracy score on the training dataset: {}'.format(accuracy_score_train))\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "# test set\n",
    "y_pred = rf.predict(X_test)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test, pos_label=1)\n",
    "accuracy_score_test = rf.score(X_test, y_test)\n",
    "print('\\nAccuracy score on the test dataset: {:.5f}'.format(accuracy_score_test))\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names of the 10 most important features:\n",
      "1. activity_intensity\n",
      "2. normalized_proj_span\n",
      "3. proj_span\n",
      "4. num_Push\n",
      "5. num_Create\n",
      "6. num_PullRequest\n",
      "7. first_quater_teamsize\n",
      "8. final_teamsize\n",
      "9. num_Fork\n",
      "10. num_Issues\n"
     ]
    }
   ],
   "source": [
    "features = X.columns[:].values.tolist()\n",
    "important_features = rf.feature_importances_\n",
    "feature_index = np.argsort(important_features)[::-1]\n",
    "print('Names of the 10 most important features:')\n",
    "for n in range(10):\n",
    "    print(\"{}. {}\".format(n+1, features[feature_index[n]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training dataset: 0.9839745236016231\n",
      "Precision on train: 0.98588\n",
      "Recall on train: 0.93727\n",
      "\n",
      "Accuracy score on the test dataset: 0.85463\n",
      "Precision on test: 0.77607\n",
      "Recall on test: 0.50633\n"
     ]
    }
   ],
   "source": [
    "# dataset_1\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_tr_1, y_tr_1)\n",
    "y_pred = rf.predict(X_tr_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr_1, pos_label=1)\n",
    "accuracy_score_train = rf.score(X_tr_1, y_tr_1)\n",
    "print('Accuracy score on the training dataset: {}'.format(accuracy_score_train))\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "# test set\n",
    "y_pred = rf.predict(X_test_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test_1, pos_label=1)\n",
    "accuracy_score_test = rf.score(X_test_1, y_test_1)\n",
    "print('\\nAccuracy score on the test dataset: {:.5f}'.format(accuracy_score_test))\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test_1)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names of the 10 most important features:\n",
      "1. activity_intensity\n",
      "2. proj_span\n",
      "3. normalized_proj_span\n",
      "4. num_Create\n",
      "5. num_Push\n",
      "6. num_Delete\n",
      "7. num_PullRequest\n",
      "8. first_quater_teamsize\n",
      "9. final_teamsize\n",
      "10. num_Fork\n"
     ]
    }
   ],
   "source": [
    "features = X.columns[:].values.tolist()\n",
    "important_features = rf.feature_importances_\n",
    "feature_index = np.argsort(important_features)[::-1]\n",
    "print('Names of the 10 most important features:')\n",
    "for n in range(10):\n",
    "    print(\"{}. {}\".format(n+1, features[feature_index[n]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_linear = SVC(kernel='linear')\n",
    "# svc_linear.fit(X_tr, y_tr)\n",
    "# ca = svc_linear.score(X_tr, y_tr)\n",
    "# print('Linear SVC classification accuracy on training set: {:.5f}'.format(ca))\n",
    "# ca = svc_linear.score(X_test, y_test)\n",
    "# print('Linear SVC classification accuracy on test set: {:.5f}'.format(ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Radial Basis Function SVC classification accuracy on training set: 0.94052\n",
      "Radial Basis Function SVC classification accuracy on test set: 0.92977\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "svc_rbf = SVC(kernel='rbf')\n",
    "svc_rbf.fit(X_tr, y_tr)\n",
    "ca = svc_rbf.score(X_tr, y_tr)\n",
    "print('\\nRadial Basis Function SVC classification accuracy on training set: {:.5f}'.format(ca))\n",
    "ca = svc_rbf.score(X_test, y_test)\n",
    "print('Radial Basis Function SVC classification accuracy on test set: {:.5f}'.format(ca))\n",
    "\n",
    "# svc_poly = SVC(kernel='poly')\n",
    "# svc_poly.fit(X_tr, y_tr)\n",
    "# ca = svc_poly.score(X_tr, y_tr)\n",
    "# print('\\nPolynomial SVC classification accuracy on training set: {:.5f}'.format(ca))\n",
    "# ca = svc_poly.score(X_test, y_test)\n",
    "# print('Polynomial SVC classification accuracy on test set: {:.5f}'.format(ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on train: 0.95098\n",
      "Recall on train: 0.07760\n",
      "Precision on test: 0.33333\n",
      "Recall on test: 0.00342\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc_rbf.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "y_pred = svc_rbf.predict(X_test)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test, pos_label=1)\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Radial Basis Function SVC classification accuracy on training set: 0.83877\n",
      "Radial Basis Function SVC classification accuracy on test set: 0.81663\n"
     ]
    }
   ],
   "source": [
    "svc_rbf = SVC(kernel='rbf')\n",
    "svc_rbf.fit(X_tr_1, y_tr_1)\n",
    "ca = svc_rbf.score(X_tr_1, y_tr_1)\n",
    "print('\\nRadial Basis Function SVC classification accuracy on training set: {:.5f}'.format(ca))\n",
    "ca = svc_rbf.score(X_test_1, y_test_1)\n",
    "print('Radial Basis Function SVC classification accuracy on test set: {:.5f}'.format(ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on train: 0.88381\n",
      "Recall on train: 0.26922\n",
      "Precision on test: 0.87347\n",
      "Recall on test: 0.22574\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc_rbf.predict(X_tr_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr_1, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "y_pred = svc_rbf.predict(X_test_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test_1, pos_label=1)\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/lib64/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "\n",
    "# Your code goes here\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8086, 100)\n",
      "(2461, 100)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = pd.read_csv('span_feb_28.csv',delimiter = ',')\n",
    "data_neg = dataset1.loc[(dataset1['class']==0) & (dataset1['proj_span']>=30.0) & (dataset1['final_teamsize'] >= 2)]\n",
    "data_pos = dataset1.loc[(dataset1['class']==1) & (dataset1['proj_span']>=30.0) & (dataset1['final_teamsize'] >= 2)]\n",
    "print(data_neg.shape)\n",
    "print(data_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('span_feb_28.csv',delimiter = ',')\n",
    "dataset = dataset.loc[(dataset['proj_span'] >= 30.0) & (dataset['final_teamsize'] >= 2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10547, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = (dataset.drop('class', axis=1)).drop('id', axis=1)\n",
    "y = dataset['class']\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_intensity</th>\n",
       "      <th>activity_intensity_Q1</th>\n",
       "      <th>activity_intensity_Q2</th>\n",
       "      <th>activity_intensity_Q3</th>\n",
       "      <th>activity_intensity_Q4</th>\n",
       "      <th>class</th>\n",
       "      <th>contribution_30_10_percentage</th>\n",
       "      <th>contribution_50_30_percentage</th>\n",
       "      <th>contribution_below_10_percentage</th>\n",
       "      <th>contribution_over_50</th>\n",
       "      <th>...</th>\n",
       "      <th>num_TeamAdd_Q4</th>\n",
       "      <th>num_Watch</th>\n",
       "      <th>num_Watch_Q1</th>\n",
       "      <th>num_Watch_Q2</th>\n",
       "      <th>num_Watch_Q3</th>\n",
       "      <th>num_Watch_Q4</th>\n",
       "      <th>num_joint_project</th>\n",
       "      <th>num_joint_success_project</th>\n",
       "      <th>proj_span</th>\n",
       "      <th>team_age_in_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "      <td>10547.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.215348</td>\n",
       "      <td>0.259294</td>\n",
       "      <td>0.210542</td>\n",
       "      <td>0.210691</td>\n",
       "      <td>0.206053</td>\n",
       "      <td>0.233336</td>\n",
       "      <td>0.091162</td>\n",
       "      <td>0.123078</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.690338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018773</td>\n",
       "      <td>2.070541</td>\n",
       "      <td>1.906324</td>\n",
       "      <td>1.773206</td>\n",
       "      <td>1.870769</td>\n",
       "      <td>1.886887</td>\n",
       "      <td>1.210581</td>\n",
       "      <td>0.276287</td>\n",
       "      <td>342.222338</td>\n",
       "      <td>9.024746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.589705</td>\n",
       "      <td>1.313745</td>\n",
       "      <td>0.602704</td>\n",
       "      <td>0.636025</td>\n",
       "      <td>0.525491</td>\n",
       "      <td>0.422975</td>\n",
       "      <td>0.178907</td>\n",
       "      <td>0.273893</td>\n",
       "      <td>0.155117</td>\n",
       "      <td>0.462376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155280</td>\n",
       "      <td>12.556466</td>\n",
       "      <td>11.399548</td>\n",
       "      <td>10.519051</td>\n",
       "      <td>11.623849</td>\n",
       "      <td>11.654193</td>\n",
       "      <td>1.002902</td>\n",
       "      <td>0.620078</td>\n",
       "      <td>331.719348</td>\n",
       "      <td>70.727458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027145</td>\n",
       "      <td>0.026857</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.025381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.069790</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.067524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.195079</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.189798</td>\n",
       "      <td>0.184333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.613683</td>\n",
       "      <td>108.911357</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>38.789862</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1590.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       activity_intensity  activity_intensity_Q1  activity_intensity_Q2  \\\n",
       "count        10547.000000           10547.000000           10547.000000   \n",
       "mean             0.215348               0.259294               0.210542   \n",
       "std              0.589705               1.313745               0.602704   \n",
       "min              0.001468               0.001468               0.001468   \n",
       "25%              0.027027               0.027145               0.026857   \n",
       "50%              0.070796               0.071429               0.069790   \n",
       "75%              0.195079               0.200000               0.187500   \n",
       "max             29.613683             108.911357              25.500000   \n",
       "\n",
       "       activity_intensity_Q3  activity_intensity_Q4         class  \\\n",
       "count           10547.000000           10547.000000  10547.000000   \n",
       "mean                0.210691               0.206053      0.233336   \n",
       "std                 0.636025               0.525491      0.422975   \n",
       "min                 0.001468               0.001468      0.000000   \n",
       "25%                 0.026882               0.025381      0.000000   \n",
       "50%                 0.070000               0.067524      0.000000   \n",
       "75%                 0.189798               0.184333      0.000000   \n",
       "max                38.789862              15.625000      1.000000   \n",
       "\n",
       "       contribution_30_10_percentage  contribution_50_30_percentage  \\\n",
       "count                   10547.000000                   10547.000000   \n",
       "mean                        0.091162                       0.123078   \n",
       "std                         0.178907                       0.273893   \n",
       "min                         0.000000                       0.000000   \n",
       "25%                         0.000000                       0.000000   \n",
       "50%                         0.000000                       0.000000   \n",
       "75%                         0.111111                       0.076923   \n",
       "max                         1.000000                       1.000000   \n",
       "\n",
       "       contribution_below_10_percentage  contribution_over_50  \\\n",
       "count                      10547.000000          10547.000000   \n",
       "mean                           0.074800              0.690338   \n",
       "std                            0.155117              0.462376   \n",
       "min                            0.000000              0.000000   \n",
       "25%                            0.000000              0.000000   \n",
       "50%                            0.006061              1.000000   \n",
       "75%                            0.076923              1.000000   \n",
       "max                            1.000000              1.000000   \n",
       "\n",
       "             ...         num_TeamAdd_Q4     num_Watch  num_Watch_Q1  \\\n",
       "count        ...           10547.000000  10547.000000  10547.000000   \n",
       "mean         ...               0.018773      2.070541      1.906324   \n",
       "std          ...               0.155280     12.556466     11.399548   \n",
       "min          ...               0.000000      0.000000      0.000000   \n",
       "25%          ...               0.000000      0.000000      0.000000   \n",
       "50%          ...               0.000000      0.000000      0.000000   \n",
       "75%          ...               0.000000      1.000000      1.000000   \n",
       "max          ...               3.000000    607.000000    607.000000   \n",
       "\n",
       "       num_Watch_Q2  num_Watch_Q3  num_Watch_Q4  num_joint_project  \\\n",
       "count  10547.000000  10547.000000  10547.000000       10547.000000   \n",
       "mean       1.773206      1.870769      1.886887           1.210581   \n",
       "std       10.519051     11.623849     11.654193           1.002902   \n",
       "min        0.000000      0.000000      0.000000           1.000000   \n",
       "25%        0.000000      0.000000      0.000000           1.000000   \n",
       "50%        0.000000      0.000000      0.000000           1.000000   \n",
       "75%        1.000000      1.000000      1.000000           1.000000   \n",
       "max      607.000000    607.000000    607.000000          26.000000   \n",
       "\n",
       "       num_joint_success_project     proj_span  team_age_in_days  \n",
       "count               10547.000000  10547.000000      10547.000000  \n",
       "mean                    0.276287    342.222338          9.024746  \n",
       "std                     0.620078    331.719348         70.727458  \n",
       "min                     0.000000     30.000000          0.000000  \n",
       "25%                     0.000000     97.000000          0.000000  \n",
       "50%                     0.000000    227.000000          0.000000  \n",
       "75%                     0.000000    475.000000          0.000000  \n",
       "max                    25.000000   1800.000000       1590.000000  \n",
       "\n",
       "[8 rows x 99 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size:  6327\n",
      "validation size:  2110\n",
      "test size:  2110\n"
     ]
    }
   ],
   "source": [
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.2, random_state=20190101)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_tr, y_tr, test_size=0.25, random_state=20190101)\n",
    "print('training size: ', X_tr.shape[0])\n",
    "print('validation size: ', X_val.shape[0])\n",
    "print('test size: ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "ax1 = sns.countplot(x='class', data=dataset)\n",
    "ax1.set_xticklabels(['not Success', 'Success'])\n",
    "plt.title('Dataset with CRAN before GH')\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "sns.countplot(x='class', data=dataset1)\n",
    "ax2.set_xticklabels(['not Success', 'Success'])\n",
    "plt.title('Dataset don\\'t care CRAN before GH')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of the LogisticRegression classifier on training set: 0.77398\n",
      "Precision on train: 0.00000\n",
      "Recall on train: 0.00000\n",
      "\n",
      "Classification accuracy of the LogisticRegression classifier on val set: 0.74787\n",
      "Precision on val: 0.00000\n",
      "Recall on val: 0.00000\n",
      "\n",
      "Classification accuracy of the LogisticRegression classifier on test set: 0.76351\n",
      "Precision on val: 0.00000\n",
      "Recall on val: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "d = DummyClassifier(strategy='most_frequent')\n",
    "d.fit(X_tr, y_tr)\n",
    "ca = d.score(X_tr, y_tr)\n",
    "print('Classification accuracy of the LogisticRegression classifier on training set: {:.5f}'.format(ca))\n",
    "y_pred = d.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "ca = d.score(X_val, y_val)\n",
    "y_pred = d.predict(X_val)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_val, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_val, pos_label=1)\n",
    "print('\\nClassification accuracy of the LogisticRegression classifier on val set: {:.5f}'.format(ca))\n",
    "print('Precision on val: {:.5f}'.format(p))\n",
    "print('Recall on val: {:.5f}'.format(r))\n",
    "ca = d.score(X_test, y_test)\n",
    "y_pred = d.predict(X_test)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test, pos_label=1)\n",
    "print('\\nClassification accuracy of the LogisticRegression classifier on test set: {:.5f}'.format(ca))\n",
    "print('Precision on val: {:.5f}'.format(p))\n",
    "print('Recall on val: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of the LogisticRegression classifier on training set: 0.81097\n",
      "Precision on train: 0.73780\n",
      "Recall on train: 0.25385\n",
      "\n",
      "Classification accuracy of the LogisticRegression classifier on val set: 0.78720\n",
      "Precision on val: 0.74850\n",
      "Recall on val: 0.23496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1486,  125],\n",
       "       [ 457,   42]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_tr, y_tr)\n",
    "ca = lr.score(X_tr, y_tr)\n",
    "print('Classification accuracy of the LogisticRegression classifier on training set: {:.5f}'.format(ca))\n",
    "y_pred = lr.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "ca = lr.score(X_val, y_val)\n",
    "y_pred = lr.predict(X_val)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_val, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_val, pos_label=1)\n",
    "print('\\nClassification accuracy of the LogisticRegression classifier on val set: {:.5f}'.format(ca))\n",
    "print('Precision on val: {:.5f}'.format(p))\n",
    "print('Recall on val: {:.5f}'.format(r))\n",
    "confusion_matrix(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.46247303e-01 -1.69863342e-01 -1.43627767e-01 -1.44630022e-01\n",
      "  -1.40829671e-01 -6.53113734e-02 -9.01481077e-02 -2.38951614e-02\n",
      "  -3.82085838e-01 -2.91641881e-02 -2.91641881e-02 -2.73398635e-01\n",
      "  -3.68333308e-01  8.51070708e-07 -3.72590560e-02 -3.33869339e-02\n",
      "  -3.31591208e-02 -3.25406470e-02 -4.17882942e-02  3.32409374e-02\n",
      "   8.04508943e-03 -9.44111682e-03  6.44812423e-02  2.25209418e-02\n",
      "  -5.07680214e-02 -3.66538947e-02 -2.37326038e-02 -1.60719512e-02\n",
      "  -4.13314450e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  2.11362767e-02 -3.69526140e-02\n",
      "  -5.53859119e-02 -1.40073816e-04  2.21470373e-02 -2.97633079e-02\n",
      "  -3.10159812e-04 -8.97210430e-02  6.78788505e-03  1.38024003e-02\n",
      "   4.69265551e-02  4.43008813e-02 -5.29647097e-02 -7.66670017e-02\n",
      "  -1.07209782e-02  3.08038569e-02  6.64118189e-02  1.29539833e-02\n",
      "   1.27246644e-02 -3.28088580e-03 -7.40540156e-02 -7.18173201e-02\n",
      "  -6.21950418e-02 -6.73629703e-02 -7.12013117e-02 -2.83300481e-02\n",
      "  -2.78866248e-02 -2.75487491e-02 -2.72516638e-02 -2.88776852e-02\n",
      "  -2.98859832e-02 -3.40872037e-02 -4.33652033e-02  4.13238278e-03\n",
      "   7.02368549e-02  5.92259998e-03 -4.63551987e-05  2.57612803e-02\n",
      "  -3.20875095e-02  4.43793177e-02  1.86944779e-02 -2.60360775e-02\n",
      "   2.08675253e-02 -1.55374924e-02 -2.33107904e-03  2.28246365e-02\n",
      "   2.32994777e-02  5.38971187e-03  2.38912928e-02  2.53810271e-02\n",
      "  -1.21471833e-02 -1.20387635e-02 -1.08103728e-02 -1.19517220e-02\n",
      "  -1.21726622e-02  8.76652016e-02 -9.48813489e-03 -8.16348025e-02\n",
      "  -4.69801374e-02  1.16885070e-01 -6.17029739e-01  7.69558713e-01\n",
      "   1.55320404e-03  2.11035310e-03]]\n",
      "[-0.55753603]\n"
     ]
    }
   ],
   "source": [
    "# display coef for logistic regression model\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(solver='lbfgs')\n",
    "# lr.fit(X_tr, y_tr)\n",
    "# predictions = lr.predict(X_tr)\n",
    "# params = np.append(lr.intercept_, lr.coef_)\n",
    "# newX = pd.DataFrame({\"Constant\":np.ones(len(X_tr))}).join(pd.DataFrame(X_tr.reset_index(drop=True)))\n",
    "# MSE = (sum((y_tr-predictions)**2))/(len(newX)-len(newX.columns))\n",
    "\n",
    "\n",
    "# var_b = MSE*(np.linalg.inv(np.dot(newX.T,newX)).diagonal())\n",
    "# sd_b = np.sqrt(var_b)\n",
    "# ts_b = params/ sd_b\n",
    "# print(newX)\n",
    "# p_values =[2*(1-stats.t.cdf(np.abs(i),(len(newX)-1))) for i in ts_b]\n",
    "\n",
    "# sd_b = np.round(sd_b,3)\n",
    "# ts_b = np.round(ts_b,3)\n",
    "# p_values = np.round(p_values,3)\n",
    "# params = np.round(params,4)\n",
    "\n",
    "# myDF3 = pd.DataFrame()\n",
    "# myDF3[\"Coefficients\"],myDF3[\"Standard Errors\"],myDF3[\"t values\"],myDF3[\"Probabilites\"] = [params,sd_b,ts_b,p_values]\n",
    "# print(myDF3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test_1)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_tr)\n",
    "X_tr = ss.transform(X_tr)\n",
    "X_test = ss.transform(X_test)\n",
    "X_val = ss.transform(X_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of the LogisticRegression classifier on training set: 0.99542\n",
      "Precision on train: 0.98883\n",
      "Recall on train: 0.99091\n",
      "\n",
      "Classification accuracy of the LogisticRegression classifier on val set: 0.98910\n",
      "Precision on val: 0.97393\n",
      "Recall on val: 0.98308\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_tr, y_tr)\n",
    "ca = lr.score(X_tr, y_tr)\n",
    "print('Classification accuracy of the LogisticRegression classifier on training set: {:.5f}'.format(ca))\n",
    "y_pred = lr.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "ca = lr.score(X_val, y_val)\n",
    "y_pred = lr.predict(X_val)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_val, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_val, pos_label=1)\n",
    "print('\\nClassification accuracy of the LogisticRegression classifier on val set: {:.5f}'.format(ca))\n",
    "print('Precision on val: {:.5f}'.format(p))\n",
    "print('Recall on val: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.35170437e-02  9.30521023e-03  7.77322483e-02  3.23467558e-02\n",
      "  -4.35336860e-02  9.03546975e-02  2.76022360e-01  3.28259867e-02\n",
      "  -5.63247270e-02  4.47699568e-03  4.47699568e-03  2.47416219e-02\n",
      "   2.66628748e-01  1.86052317e-01 -1.37109849e-02 -3.25581461e-02\n",
      "   4.16290209e-02  5.44920882e-02 -4.90668583e-02  1.39809107e-02\n",
      "   1.23091523e-02  4.98584023e-02  6.79829599e-02  8.49305294e-02\n",
      "  -7.83235859e-02 -1.08337925e-02  4.34176403e-02 -7.73502239e-02\n",
      "  -4.76199790e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.18839566e-02 -1.16194878e-02\n",
      "  -7.44994480e-02 -1.03435272e-02 -3.44321077e-01 -5.14497134e-02\n",
      "   5.98626274e-02 -7.63779417e-02  5.11482407e-02  4.53160113e-02\n",
      "   5.75370957e-02  8.10243075e-02  3.33909180e-01 -8.59981526e-02\n",
      "  -1.06214554e-01  1.90329238e-01  8.68953337e-02 -2.78115851e-01\n",
      "  -1.30994724e-01 -1.36854564e-01  6.64842389e-02 -5.14699475e-02\n",
      "  -8.44162399e-02  1.99006764e-01 -6.09039162e-02  3.63471874e-02\n",
      "   6.13974247e-02 -6.10139768e-02  7.02298334e-02 -1.12345908e-01\n",
      "  -1.00935481e-01 -3.14618163e-03  1.87958241e-02 -4.47853254e-03\n",
      "  -2.84427132e-02 -4.19939502e-02  1.53145690e-01 -1.68445115e-01\n",
      "  -1.01070118e-01  2.05415732e-01  2.56933477e-01 -2.04094897e-02\n",
      "  -4.13034444e-01 -3.08022111e-03 -4.24620560e-02  8.09374458e-02\n",
      "   1.04622446e-01 -1.97782449e-01  1.27906667e-01 -4.87456695e-02\n",
      "  -4.93534247e-02 -3.69584177e-02  1.11768397e-01  3.57651511e-02\n",
      "  -7.80950372e-02 -1.40535973e-02 -9.37738232e-02  1.82973889e-01\n",
      "  -5.80139813e-02  1.08324327e-01 -3.02708495e+00  6.51011534e+00\n",
      "   1.86052317e-01 -6.12642785e-01]]\n",
      "[-3.70187333]\n"
     ]
    }
   ],
   "source": [
    "# display coef for logistic regression model\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test_1)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training dataset: 1.0\n",
      "Precision on train: 1.00000\n",
      "Recall on train: 1.00000\n",
      "\n",
      "Accuracy score on the val dataset: 0.99005\n",
      "Precision on val: 0.96203\n",
      "Recall on val: 1.00000\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_tr, y_tr)\n",
    "y_pred = rf.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "accuracy_score_train = rf.score(X_tr, y_tr)\n",
    "print('Accuracy score on the training dataset: {}'.format(accuracy_score_train))\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "# test set\n",
    "y_pred = rf.predict(X_val)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_val, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_val, pos_label=1)\n",
    "accuracy_score_val = rf.score(X_val, y_val)\n",
    "print('\\nAccuracy score on the val dataset: {:.5f}'.format(accuracy_score_val))\n",
    "print('Precision on val: {:.5f}'.format(p))\n",
    "print('Recall on val: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score on the test dataset: 0.99194\n",
      "Precision on test: 0.96887\n",
      "Recall on test: 0.99800\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "y_pred = rf.predict(X_test)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test, pos_label=1)\n",
    "accuracy_score_test = rf.score(X_test, y_test)\n",
    "print('\\nAccuracy score on the test dataset: {:.5f}'.format(accuracy_score_test))\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names of the 10 most important features:\n",
      "1. num_joint_success_project\n",
      "2. normalized_proj_span\n",
      "3. proj_span\n",
      "4. activity_intensity_Q3\n",
      "5. activity_intensity_Q4\n",
      "6. activity_intensity_Q1\n",
      "7. activity_intensity\n",
      "8. activity_intensity_Q2\n",
      "9. max_contribution_percentage\n",
      "10. num_Create_Q1\n"
     ]
    }
   ],
   "source": [
    "features = X.columns[:].values.tolist()\n",
    "important_features = rf.feature_importances_\n",
    "feature_index = np.argsort(important_features)[::-1]\n",
    "print('Names of the 10 most important features:')\n",
    "for n in range(10):\n",
    "    print(\"{}. {}\".format(n+1, features[feature_index[n]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test_1)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_linear = SVC(kernel='linear')\n",
    "# svc_linear.fit(X_tr, y_tr)\n",
    "# ca = svc_linear.score(X_tr, y_tr)\n",
    "# print('Linear SVC classification accuracy on training set: {:.5f}'.format(ca))\n",
    "# ca = svc_linear.score(X_test, y_test)\n",
    "# print('Linear SVC classification accuracy on test set: {:.5f}'.format(ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Radial Basis Function SVC classification accuracy on training set: 0.98957\n",
      "Radial Basis Function SVC classification accuracy on val set: 0.96825\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "svc_rbf = SVC(kernel='rbf')\n",
    "svc_rbf.fit(X_tr, y_tr)\n",
    "ca = svc_rbf.score(X_tr, y_tr)\n",
    "print('\\nRadial Basis Function SVC classification accuracy on training set: {:.5f}'.format(ca))\n",
    "ca = svc_rbf.score(X_val, y_val)\n",
    "print('Radial Basis Function SVC classification accuracy on val set: {:.5f}'.format(ca))\n",
    "\n",
    "# svc_poly = SVC(kernel='poly')\n",
    "# svc_poly.fit(X_tr, y_tr)\n",
    "# ca = svc_poly.score(X_tr, y_tr)\n",
    "# print('\\nPolynomial SVC classification accuracy on training set: {:.5f}'.format(ca))\n",
    "# ca = svc_poly.score(X_test, y_test)\n",
    "# print('Polynomial SVC classification accuracy on test set: {:.5f}'.format(ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on train: 0.98164\n",
      "Recall on train: 0.97203\n",
      "Precision on val: 0.96970\n",
      "Recall on val: 0.90226\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc_rbf.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "y_pred = svc_rbf.predict(X_val)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_val, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_val, pos_label=1)\n",
    "print('Precision on val: {:.5f}'.format(p))\n",
    "print('Recall on val: {:.5f}'.format(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP classification accuracy on training set: 0.99716\n",
      "Precision on train: 0.98892\n",
      "Recall on train: 0.99860\n",
      "\n",
      "MLP classification accuracy on validation set: 0.98910\n",
      "Precision on val: 0.97570\n",
      "Recall on val: 0.98120\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,2), random_state=201902)\n",
    "mlp.fit(X_tr, y_tr)\n",
    "y_pred = mlp.predict(X_tr)\n",
    "ca = mlp.score(X_tr, y_tr)\n",
    "print('\\nMLP classification accuracy on training set: {:.5f}'.format(ca))\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "y_pred = mlp.predict(X_val)\n",
    "ca = mlp.score(X_val, y_val)\n",
    "print('\\nMLP classification accuracy on validation set: {:.5f}'.format(ca))\n",
    "p = precision_score(y_pred=y_pred,y_true=y_val, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_val, pos_label=1)\n",
    "print('Precision on val: {:.5f}'.format(p))\n",
    "print('Recall on val: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10]\n",
      "\n",
      "MLP classification accuracy on training set: 0.77398\n",
      "Precision on train: 0.00000\n",
      "Recall on train: 0.00000\n",
      "\n",
      "MLP classification accuracy on validation set: 0.74787\n",
      "Precision on val: 0.00000\n",
      "Recall on val: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "test = np.repeat(10,200)\n",
    "print(test)\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(test), random_state=201902)\n",
    "mlp.fit(X_tr, y_tr)\n",
    "y_pred = mlp.predict(X_tr)\n",
    "ca = mlp.score(X_tr, y_tr)\n",
    "print('\\nMLP classification accuracy on training set: {:.5f}'.format(ca))\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "y_pred = mlp.predict(X_val)\n",
    "ca = mlp.score(X_val, y_val)\n",
    "print('\\nMLP classification accuracy on validation set: {:.5f}'.format(ca))\n",
    "p = precision_score(y_pred=y_pred,y_true=y_val, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_val, pos_label=1)\n",
    "print('Precision on val: {:.5f}'.format(p))\n",
    "print('Recall on val: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

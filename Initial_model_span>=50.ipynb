{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "\n",
    "# Your code goes here\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, recall_score, precision_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12703, 22)\n",
      "(4564, 22)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = pd.read_csv('test_1.csv',delimiter = ',')\n",
    "data_neg = dataset1.loc[(dataset1['class']==0) & (dataset1['proj_span']>=50.0)]\n",
    "data_pos = dataset1.loc[(dataset1['class']==1) & (dataset1['proj_span']>=50.0)]\n",
    "print(data_neg.shape)\n",
    "print(data_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('test.csv',delimiter = ',')\n",
    "dataset1 = pd.read_csv('test_1.csv',delimiter = ',') # this one does not take care the CRAN before GH date\n",
    "dataset = dataset.loc[dataset['proj_span'] >= 50.0]\n",
    "dataset1 = dataset1.loc[dataset1['proj_span'] >= 50.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17267, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = (dataset.drop('class', axis=1)).drop('id', axis=1)\n",
    "y = dataset['class']\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17267, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = (dataset1.drop('class', axis=1)).drop('id', axis=1)\n",
    "y_1 = dataset1['class']\n",
    "dataset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_intensity</th>\n",
       "      <th>class</th>\n",
       "      <th>final_teamsize</th>\n",
       "      <th>first_quater_teamsize</th>\n",
       "      <th>normalized_proj_span</th>\n",
       "      <th>num_CommitComment</th>\n",
       "      <th>num_Create</th>\n",
       "      <th>num_Delete</th>\n",
       "      <th>num_Fork</th>\n",
       "      <th>num_Gollum</th>\n",
       "      <th>...</th>\n",
       "      <th>num_Issues</th>\n",
       "      <th>num_Member</th>\n",
       "      <th>num_Public</th>\n",
       "      <th>num_PullRequest</th>\n",
       "      <th>num_PullRequestReviewComment</th>\n",
       "      <th>num_Push</th>\n",
       "      <th>num_Release</th>\n",
       "      <th>num_TeamAdd</th>\n",
       "      <th>num_Watch</th>\n",
       "      <th>proj_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "      <td>17267.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.161972</td>\n",
       "      <td>0.264319</td>\n",
       "      <td>6.575028</td>\n",
       "      <td>6.501071</td>\n",
       "      <td>0.156367</td>\n",
       "      <td>0.129148</td>\n",
       "      <td>1.038049</td>\n",
       "      <td>0.240111</td>\n",
       "      <td>3.513465</td>\n",
       "      <td>0.529739</td>\n",
       "      <td>...</td>\n",
       "      <td>1.623849</td>\n",
       "      <td>0.084960</td>\n",
       "      <td>0.024208</td>\n",
       "      <td>7.268257</td>\n",
       "      <td>1.543059</td>\n",
       "      <td>17.401807</td>\n",
       "      <td>0.077489</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>1.251231</td>\n",
       "      <td>285.370012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.441523</td>\n",
       "      <td>0.440983</td>\n",
       "      <td>301.426692</td>\n",
       "      <td>301.428121</td>\n",
       "      <td>0.155001</td>\n",
       "      <td>1.487038</td>\n",
       "      <td>3.072750</td>\n",
       "      <td>2.251304</td>\n",
       "      <td>292.981824</td>\n",
       "      <td>7.823614</td>\n",
       "      <td>...</td>\n",
       "      <td>11.353639</td>\n",
       "      <td>0.559573</td>\n",
       "      <td>0.196087</td>\n",
       "      <td>49.305409</td>\n",
       "      <td>28.532156</td>\n",
       "      <td>44.880187</td>\n",
       "      <td>0.809002</td>\n",
       "      <td>0.122638</td>\n",
       "      <td>9.863314</td>\n",
       "      <td>282.876253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.059880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.101370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.154930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.191233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>349.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.613683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39519.000000</td>\n",
       "      <td>39519.000000</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>38469.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4139.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "      <td>1494.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       activity_intensity         class  final_teamsize  \\\n",
       "count        17267.000000  17267.000000    17267.000000   \n",
       "mean             0.161972      0.264319        6.575028   \n",
       "std              0.441523      0.440983      301.426692   \n",
       "min              0.001468      0.000000        1.000000   \n",
       "25%              0.026087      0.000000        1.000000   \n",
       "50%              0.059880      0.000000        2.000000   \n",
       "75%              0.154930      1.000000        3.000000   \n",
       "max             29.613683      1.000000    39519.000000   \n",
       "\n",
       "       first_quater_teamsize  normalized_proj_span  num_CommitComment  \\\n",
       "count           17267.000000          17267.000000       17267.000000   \n",
       "mean                6.501071              0.156367           0.129148   \n",
       "std               301.428121              0.155001           1.487038   \n",
       "min                 0.000000              0.027397           0.000000   \n",
       "25%                 1.000000              0.053151           0.000000   \n",
       "50%                 2.000000              0.101370           0.000000   \n",
       "75%                 3.000000              0.191233           0.000000   \n",
       "max             39519.000000              0.986301          89.000000   \n",
       "\n",
       "         num_Create    num_Delete      num_Fork    num_Gollum      ...       \\\n",
       "count  17267.000000  17267.000000  17267.000000  17267.000000      ...        \n",
       "mean       1.038049      0.240111      3.513465      0.529739      ...        \n",
       "std        3.072750      2.251304    292.981824      7.823614      ...        \n",
       "min        0.000000      0.000000      0.000000      0.000000      ...        \n",
       "25%        0.000000      0.000000      0.000000      0.000000      ...        \n",
       "50%        0.000000      0.000000      0.000000      0.000000      ...        \n",
       "75%        1.000000      0.000000      1.000000      0.000000      ...        \n",
       "max      117.000000    114.000000  38469.000000    649.000000      ...        \n",
       "\n",
       "         num_Issues    num_Member    num_Public  num_PullRequest  \\\n",
       "count  17267.000000  17267.000000  17267.000000     17267.000000   \n",
       "mean       1.623849      0.084960      0.024208         7.268257   \n",
       "std       11.353639      0.559573      0.196087        49.305409   \n",
       "min        0.000000      0.000000      0.000000         0.000000   \n",
       "25%        0.000000      0.000000      0.000000         0.000000   \n",
       "50%        0.000000      0.000000      0.000000         0.000000   \n",
       "75%        0.000000      0.000000      0.000000         3.000000   \n",
       "max      401.000000     34.000000     13.000000      4139.000000   \n",
       "\n",
       "       num_PullRequestReviewComment      num_Push   num_Release   num_TeamAdd  \\\n",
       "count                  17267.000000  17267.000000  17267.000000  17267.000000   \n",
       "mean                       1.543059     17.401807      0.077489      0.011583   \n",
       "std                       28.532156     44.880187      0.809002      0.122638   \n",
       "min                        0.000000      0.000000      0.000000      0.000000   \n",
       "25%                        0.000000      1.000000      0.000000      0.000000   \n",
       "50%                        0.000000      4.000000      0.000000      0.000000   \n",
       "75%                        0.000000     16.000000      0.000000      0.000000   \n",
       "max                     2625.000000   1494.000000     54.000000      3.000000   \n",
       "\n",
       "          num_Watch     proj_span  \n",
       "count  17267.000000  17267.000000  \n",
       "mean       1.251231    285.370012  \n",
       "std        9.863314    282.876253  \n",
       "min        0.000000     50.000000  \n",
       "25%        0.000000     97.000000  \n",
       "50%        0.000000    185.000000  \n",
       "75%        0.000000    349.000000  \n",
       "max      607.000000   1800.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.3, random_state=20190101)\n",
    "X_tr_1, X_test_1, y_tr_1, y_test_1 = train_test_split(X_1, y_1, test_size=0.3, random_state=20190101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "ax1 = sns.countplot(x='class', data=dataset)\n",
    "ax1.set_xticklabels(['not Success', 'Success'])\n",
    "plt.title('Dataset with CRAN before GH')\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "sns.countplot(x='class', data=dataset1)\n",
    "ax2.set_xticklabels(['not Success', 'Success'])\n",
    "plt.title('Dataset don\\'t care CRAN before GH')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of the LogisticRegression classifier on training set: 0.91155\n",
      "Precision on train: 0.34783\n",
      "Recall on train: 0.03868\n",
      "\n",
      "Classification accuracy of the LogisticRegression classifier on test set: 0.90793\n",
      "Precision on test: 0.36508\n",
      "Recall on test: 0.05000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4681,   40],\n",
       "       [ 437,   23]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_tr, y_tr)\n",
    "ca = lr.score(X_tr, y_tr)\n",
    "print('Classification accuracy of the LogisticRegression classifier on training set: {:.5f}'.format(ca))\n",
    "y_pred = lr.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "ca = lr.score(X_test, y_test)\n",
    "y_pred = lr.predict(X_test)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test, pos_label=1)\n",
    "print('\\nClassification accuracy of the LogisticRegression classifier on test set: {:.5f}'.format(ca))\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))\n",
    "confusion_matrix(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.62911899e-01 -2.20986839e-01  1.00412238e-01  5.06838338e-07\n",
      "   1.42385575e-01  9.65309232e-02  7.52194299e-02  9.51297299e-02\n",
      "   1.22435631e-02  2.14645995e-03  9.53234856e-03 -9.84263266e-02\n",
      "  -4.52579316e-02  6.26933170e-03 -6.78721370e-03 -3.75679599e-03\n",
      "   2.05888971e-01 -4.88126579e-03  1.43931800e-01  9.24979966e-04]]\n",
      "[-2.43527536]\n"
     ]
    }
   ],
   "source": [
    "# display coef for logistic regression model\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of the LogisticRegression classifier on training set: 0.76171\n",
      "Precision on train: 0.67404\n",
      "Recall on train: 0.18213\n",
      "\n",
      "Classification accuracy of the LogisticRegression classifier on test set: 0.75526\n",
      "Precision on test: 0.65517\n",
      "Recall on test: 0.17834\n"
     ]
    }
   ],
   "source": [
    "# on dataset_1\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_tr_1, y_tr_1)\n",
    "ca = lr.score(X_tr_1, y_tr_1)\n",
    "print('Classification accuracy of the LogisticRegression classifier on training set: {:.5f}'.format(ca))\n",
    "y_pred = lr.predict(X_tr_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr_1, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "ca = lr.score(X_test_1, y_test_1)\n",
    "y_pred = lr.predict(X_test_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test_1, pos_label=1)\n",
    "print('\\nClassification accuracy of the LogisticRegression classifier on test set: {:.5f}'.format(ca))\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.96538952e-01 -9.47407009e-02  1.62899198e-01  6.70733721e-07\n",
      "   1.03728373e-02  3.36963598e-01 -1.67649038e-01 -2.45076329e-01\n",
      "  -1.76031733e-02  1.49322107e-02  8.26863954e-03 -1.17713150e-01\n",
      "  -7.93387972e-02 -1.79052975e-03  8.82665276e-04 -1.54745635e-02\n",
      "  -5.48425743e-04 -1.84384374e-02 -2.99514535e-02  1.22408904e-03]]\n",
      "[-1.45815513]\n"
     ]
    }
   ],
   "source": [
    "# display coef for logistic regression model\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test_1)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_tr)\n",
    "X_tr = ss.transform(X_tr)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "ss1 = StandardScaler()\n",
    "ss1.fit(X_tr_1)\n",
    "X_tr_1 = ss.transform(X_tr_1)\n",
    "X_test_1 = ss.transform(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of the LogisticRegression classifier on training set: 0.91469\n",
      "Precision on train: 0.52055\n",
      "Recall on train: 0.03675\n",
      "\n",
      "Classification accuracy of the LogisticRegression classifier on test set: 0.90909\n",
      "Precision on test: 0.34286\n",
      "Recall on test: 0.02609\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_tr, y_tr)\n",
    "ca = lr.score(X_tr, y_tr)\n",
    "print('Classification accuracy of the LogisticRegression classifier on training set: {:.5f}'.format(ca))\n",
    "y_pred = lr.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "ca = lr.score(X_test, y_test)\n",
    "y_pred = lr.predict(X_test)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test, pos_label=1)\n",
    "print('\\nClassification accuracy of the LogisticRegression classifier on test set: {:.5f}'.format(ca))\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11573549  0.00261494  0.07814995  0.20344746  0.0600677   0.40893433\n",
      "  -0.2954268  -1.70065353 -0.07686108 -0.11134191  0.2114973  -0.02920636\n",
      "  -0.05133449  0.08888731 -0.03342336 -0.08913198 -0.04338815  0.02139931\n",
      "   0.05533942  0.20344746]]\n",
      "[-2.5161522]\n"
     ]
    }
   ],
   "source": [
    "# display coef for logistic regression model\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of the LogisticRegression classifier on training set: 0.76485\n",
      "Precision on train: 0.71089\n",
      "Recall on train: 0.17867\n",
      "\n",
      "Classification accuracy of the LogisticRegression classifier on test set: 0.76298\n",
      "Precision on test: 0.71625\n",
      "Recall on test: 0.18773\n"
     ]
    }
   ],
   "source": [
    "# on dataset_1\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_tr_1, y_tr_1)\n",
    "ca = lr.score(X_tr_1, y_tr_1)\n",
    "print('Classification accuracy of the LogisticRegression classifier on training set: {:.5f}'.format(ca))\n",
    "y_pred = lr.predict(X_tr_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr_1, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "ca = lr.score(X_test_1, y_test_1)\n",
    "y_pred = lr.predict(X_test_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test_1, pos_label=1)\n",
    "print('\\nClassification accuracy of the LogisticRegression classifier on test set: {:.5f}'.format(ca))\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.23086065e-01 -9.83476879e-01 -7.81302545e-01  1.26731695e-01\n",
      "  -1.63924885e-02  1.11327238e+00 -2.78721543e-01 -2.99189880e+00\n",
      "  -1.67990109e-01  1.78272003e-01  3.51699965e-01 -1.67751928e-01\n",
      "  -2.72089311e-01  2.21301657e-01  9.40039735e-02 -4.47637388e-01\n",
      "  -2.32324605e-01 -7.89261209e-02  1.40387874e-03  1.26731695e-01]]\n",
      "[-1.21457353]\n"
     ]
    }
   ],
   "source": [
    "# display coef for logistic regression model\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test_1)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training dataset: 0.996938606652325\n",
      "Precision on train: 0.99701\n",
      "Recall on train: 0.96712\n",
      "\n",
      "Accuracy score on the test dataset: 0.91237\n",
      "Precision on test: 0.52459\n",
      "Recall on test: 0.13913\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_tr, y_tr)\n",
    "y_pred = rf.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "accuracy_score_train = rf.score(X_tr, y_tr)\n",
    "print('Accuracy score on the training dataset: {}'.format(accuracy_score_train))\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "# test set\n",
    "y_pred = rf.predict(X_test)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test, pos_label=1)\n",
    "accuracy_score_test = rf.score(X_test, y_test)\n",
    "print('\\nAccuracy score on the test dataset: {:.5f}'.format(accuracy_score_test))\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names of the 10 most important features:\n",
      "1. activity_intensity\n",
      "2. normalized_proj_span\n",
      "3. proj_span\n",
      "4. num_Push\n",
      "5. num_PullRequest\n",
      "6. num_Create\n",
      "7. first_quater_teamsize\n",
      "8. final_teamsize\n",
      "9. num_PullRequestReviewComment\n",
      "10. num_Fork\n"
     ]
    }
   ],
   "source": [
    "features = X.columns[:].values.tolist()\n",
    "important_features = rf.feature_importances_\n",
    "feature_index = np.argsort(important_features)[::-1]\n",
    "print('Names of the 10 most important features:')\n",
    "for n in range(10):\n",
    "    print(\"{}. {}\".format(n+1, features[feature_index[n]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training dataset: 0.9918087042859507\n",
      "Precision on train: 0.98827\n",
      "Recall on train: 0.98050\n",
      "\n",
      "Accuracy score on the test dataset: 0.81857\n",
      "Precision on test: 0.73545\n",
      "Recall on test: 0.50181\n"
     ]
    }
   ],
   "source": [
    "# dataset_1\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_tr_1, y_tr_1)\n",
    "y_pred = rf.predict(X_tr_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr_1, pos_label=1)\n",
    "accuracy_score_train = rf.score(X_tr_1, y_tr_1)\n",
    "print('Accuracy score on the training dataset: {}'.format(accuracy_score_train))\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "# test set\n",
    "y_pred = rf.predict(X_test_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test_1, pos_label=1)\n",
    "accuracy_score_test = rf.score(X_test_1, y_test_1)\n",
    "print('\\nAccuracy score on the test dataset: {:.5f}'.format(accuracy_score_test))\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test_1)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names of the 10 most important features:\n",
      "1. activity_intensity\n",
      "2. normalized_proj_span\n",
      "3. num_Create\n",
      "4. proj_span\n",
      "5. num_Push\n",
      "6. num_PullRequest\n",
      "7. first_quater_teamsize\n",
      "8. final_teamsize\n",
      "9. num_Fork\n",
      "10. num_Watch\n"
     ]
    }
   ],
   "source": [
    "features = X.columns[:].values.tolist()\n",
    "important_features = rf.feature_importances_\n",
    "feature_index = np.argsort(important_features)[::-1]\n",
    "print('Names of the 10 most important features:')\n",
    "for n in range(10):\n",
    "    print(\"{}. {}\".format(n+1, features[feature_index[n]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_linear = SVC(kernel='linear')\n",
    "# svc_linear.fit(X_tr, y_tr)\n",
    "# ca = svc_linear.score(X_tr, y_tr)\n",
    "# print('Linear SVC classification accuracy on training set: {:.5f}'.format(ca))\n",
    "# ca = svc_linear.score(X_test, y_test)\n",
    "# print('Linear SVC classification accuracy on test set: {:.5f}'.format(ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Radial Basis Function SVC classification accuracy on training set: 0.91991\n",
      "Radial Basis Function SVC classification accuracy on test set: 0.91141\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "svc_rbf = SVC(kernel='rbf')\n",
    "svc_rbf.fit(X_tr, y_tr)\n",
    "ca = svc_rbf.score(X_tr, y_tr)\n",
    "print('\\nRadial Basis Function SVC classification accuracy on training set: {:.5f}'.format(ca))\n",
    "ca = svc_rbf.score(X_test, y_test)\n",
    "print('Radial Basis Function SVC classification accuracy on test set: {:.5f}'.format(ca))\n",
    "\n",
    "# svc_poly = SVC(kernel='poly')\n",
    "# svc_poly.fit(X_tr, y_tr)\n",
    "# ca = svc_poly.score(X_tr, y_tr)\n",
    "# print('\\nPolynomial SVC classification accuracy on training set: {:.5f}'.format(ca))\n",
    "# ca = svc_poly.score(X_test, y_test)\n",
    "# print('Polynomial SVC classification accuracy on test set: {:.5f}'.format(ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on train: 0.97143\n",
      "Recall on train: 0.06576\n",
      "Precision on test: 0.66667\n",
      "Recall on test: 0.00435\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc_rbf.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "y_pred = svc_rbf.predict(X_test)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test, pos_label=1)\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Radial Basis Function SVC classification accuracy on training set: 0.78893\n",
      "Radial Basis Function SVC classification accuracy on test set: 0.77591\n"
     ]
    }
   ],
   "source": [
    "svc_rbf = SVC(kernel='rbf')\n",
    "svc_rbf.fit(X_tr_1, y_tr_1)\n",
    "ca = svc_rbf.score(X_tr_1, y_tr_1)\n",
    "print('\\nRadial Basis Function SVC classification accuracy on training set: {:.5f}'.format(ca))\n",
    "ca = svc_rbf.score(X_test_1, y_test_1)\n",
    "print('Radial Basis Function SVC classification accuracy on test set: {:.5f}'.format(ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on train: 0.85845\n",
      "Recall on train: 0.23655\n",
      "Precision on test: 0.80601\n",
      "Recall on test: 0.21300\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc_rbf.predict(X_tr_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr_1, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "y_pred = svc_rbf.predict(X_test_1)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_test_1, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_test_1, pos_label=1)\n",
    "print('Precision on test: {:.5f}'.format(p))\n",
    "print('Recall on test: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "\n",
    "# Your code goes here\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, recall_score, precision_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21820, 96)\n",
      "(5993, 96)\n"
     ]
    }
   ],
   "source": [
    "dataset_original = pd.read_csv('span_feb_24.csv',delimiter = ',')\n",
    "dataset_original = dataset_original.loc[dataset_original['proj_span'] >= 10.0]\n",
    "\n",
    "dataset1 = pd.read_csv('span_fir_quater_feb_24.csv',delimiter = ',')\n",
    "data_neg = dataset1.loc[(dataset1['class']==0) & (dataset1['id'].isin(dataset_original['id']))]\n",
    "data_pos = dataset1.loc[(dataset1['class']==1) & (dataset1['id'].isin(dataset_original['id']))]\n",
    "print(data_neg.shape)\n",
    "print(data_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('span_fir_quater_feb_24.csv',delimiter = ',')\n",
    "dataset = dataset.loc[dataset['id'].isin(dataset_original['id'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27813, 96)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = (dataset.drop('class', axis=1)).drop('id', axis=1)\n",
    "y = dataset['class']\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_intensity</th>\n",
       "      <th>class</th>\n",
       "      <th>contribution_30_10</th>\n",
       "      <th>contribution_50_30</th>\n",
       "      <th>contribution_below_10</th>\n",
       "      <th>contribution_over_50</th>\n",
       "      <th>final_teamsize</th>\n",
       "      <th>first_quater_teamsize</th>\n",
       "      <th>majority_contribution_time</th>\n",
       "      <th>max_contribution_percentage</th>\n",
       "      <th>...</th>\n",
       "      <th>num_TeamAdd_Q4</th>\n",
       "      <th>num_Watch</th>\n",
       "      <th>num_Watch_Q1</th>\n",
       "      <th>num_Watch_Q2</th>\n",
       "      <th>num_Watch_Q3</th>\n",
       "      <th>num_Watch_Q4</th>\n",
       "      <th>num_joint_project</th>\n",
       "      <th>num_joint_success_project</th>\n",
       "      <th>proj_span</th>\n",
       "      <th>team_age_in_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "      <td>27813.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.916007</td>\n",
       "      <td>0.215475</td>\n",
       "      <td>0.337540</td>\n",
       "      <td>0.261065</td>\n",
       "      <td>3.107827</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>4.565419</td>\n",
       "      <td>4.565419</td>\n",
       "      <td>0.545680</td>\n",
       "      <td>0.848609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.203826</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.068961</td>\n",
       "      <td>0.072376</td>\n",
       "      <td>0.059145</td>\n",
       "      <td>828.326358</td>\n",
       "      <td>814.016647</td>\n",
       "      <td>23.956172</td>\n",
       "      <td>53.731277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.454765</td>\n",
       "      <td>0.411159</td>\n",
       "      <td>0.831806</td>\n",
       "      <td>0.615824</td>\n",
       "      <td>237.373068</td>\n",
       "      <td>0.348041</td>\n",
       "      <td>237.364690</td>\n",
       "      <td>237.364690</td>\n",
       "      <td>0.497918</td>\n",
       "      <td>0.218953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>2.555817</td>\n",
       "      <td>0.797873</td>\n",
       "      <td>0.660730</td>\n",
       "      <td>0.771995</td>\n",
       "      <td>0.665123</td>\n",
       "      <td>2738.267131</td>\n",
       "      <td>2731.359397</td>\n",
       "      <td>65.819460</td>\n",
       "      <td>141.433467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>256.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39495.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39495.000000</td>\n",
       "      <td>39495.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>10064.000000</td>\n",
       "      <td>10033.000000</td>\n",
       "      <td>1473.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       activity_intensity         class  contribution_30_10  \\\n",
       "count        27813.000000  27813.000000        27813.000000   \n",
       "mean             1.916007      0.215475            0.337540   \n",
       "std              3.454765      0.411159            0.831806   \n",
       "min              0.001358      0.000000            0.000000   \n",
       "25%              0.400000      0.000000            0.000000   \n",
       "50%              1.000000      0.000000            0.000000   \n",
       "75%              2.000000      0.000000            0.000000   \n",
       "max            256.666667      1.000000            9.000000   \n",
       "\n",
       "       contribution_50_30  contribution_below_10  contribution_over_50  \\\n",
       "count        27813.000000           27813.000000          27813.000000   \n",
       "mean             0.261065               3.107827              0.858987   \n",
       "std              0.615824             237.373068              0.348041   \n",
       "min              0.000000               0.000000              0.000000   \n",
       "25%              0.000000               0.000000              1.000000   \n",
       "50%              0.000000               0.000000              1.000000   \n",
       "75%              0.000000               0.000000              1.000000   \n",
       "max              3.000000           39495.000000              1.000000   \n",
       "\n",
       "       final_teamsize  first_quater_teamsize  majority_contribution_time  \\\n",
       "count    27813.000000           27813.000000                27813.000000   \n",
       "mean         4.565419               4.565419                    0.545680   \n",
       "std        237.364690             237.364690                    0.497918   \n",
       "min          1.000000               1.000000                    0.000000   \n",
       "25%          1.000000               1.000000                    0.000000   \n",
       "50%          1.000000               1.000000                    1.000000   \n",
       "75%          2.000000               2.000000                    1.000000   \n",
       "max      39495.000000           39495.000000                    1.000000   \n",
       "\n",
       "       max_contribution_percentage        ...         num_TeamAdd_Q4  \\\n",
       "count                 27813.000000        ...           27813.000000   \n",
       "mean                      0.848609        ...               0.000935   \n",
       "std                       0.218953        ...               0.030561   \n",
       "min                       0.000747        ...               0.000000   \n",
       "25%                       0.714286        ...               0.000000   \n",
       "50%                       1.000000        ...               0.000000   \n",
       "75%                       1.000000        ...               0.000000   \n",
       "max                       1.000000        ...               1.000000   \n",
       "\n",
       "          num_Watch  num_Watch_Q1  num_Watch_Q2  num_Watch_Q3  num_Watch_Q4  \\\n",
       "count  27813.000000  27813.000000  27813.000000  27813.000000  27813.000000   \n",
       "mean       0.203826      0.054902      0.068961      0.072376      0.059145   \n",
       "std        2.555817      0.797873      0.660730      0.771995      0.665123   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      198.000000     78.000000     46.000000     46.000000     54.000000   \n",
       "\n",
       "       num_joint_project  num_joint_success_project     proj_span  \\\n",
       "count       27813.000000               27813.000000  27813.000000   \n",
       "mean          828.326358                 814.016647     23.956172   \n",
       "std          2738.267131                2731.359397     65.819460   \n",
       "min             1.000000                   0.000000      1.000000   \n",
       "25%             1.000000                   0.000000      1.000000   \n",
       "50%             1.000000                   0.000000      1.000000   \n",
       "75%             5.000000                   1.000000     14.000000   \n",
       "max         10064.000000               10033.000000   1473.000000   \n",
       "\n",
       "       team_age_in_days  \n",
       "count      27813.000000  \n",
       "mean          53.731277  \n",
       "std          141.433467  \n",
       "min            0.000000  \n",
       "25%            0.000000  \n",
       "50%            0.000000  \n",
       "75%           35.000000  \n",
       "max         1718.000000  \n",
       "\n",
       "[8 rows x 95 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size:  16687\n",
      "validation size:  5563\n",
      "test size:  5563\n"
     ]
    }
   ],
   "source": [
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.2, random_state=20190101)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_tr, y_tr, test_size=0.25, random_state=20190101)\n",
    "print('training size: ', X_tr.shape[0])\n",
    "print('validation size: ', X_val.shape[0])\n",
    "print('test size: ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "ax1 = sns.countplot(x='class', data=dataset)\n",
    "ax1.set_xticklabels(['not Success', 'Success'])\n",
    "plt.title('Dataset with CRAN before GH')\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "sns.countplot(x='class', data=dataset1)\n",
    "ax2.set_xticklabels(['not Success', 'Success'])\n",
    "plt.title('Dataset don\\'t care CRAN before GH')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of the LogisticRegression classifier on training set: 0.86654\n",
      "Precision on train: 0.96218\n",
      "Recall on train: 0.38737\n",
      "\n",
      "Classification accuracy of the LogisticRegression classifier on val set: 0.86698\n",
      "Precision on val: 0.95082\n",
      "Recall on val: 0.39322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3914,  383],\n",
       "       [1161,  105]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_tr, y_tr)\n",
    "ca = lr.score(X_tr, y_tr)\n",
    "print('Classification accuracy of the LogisticRegression classifier on training set: {:.5f}'.format(ca))\n",
    "y_pred = lr.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "ca = lr.score(X_val, y_val)\n",
    "y_pred = lr.predict(X_val)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_val, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_val, pos_label=1)\n",
    "print('\\nClassification accuracy of the LogisticRegression classifier on val set: {:.5f}'.format(ca))\n",
    "print('Precision on val: {:.5f}'.format(p))\n",
    "print('Recall on val: {:.5f}'.format(r))\n",
    "confusion_matrix(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.13552082e-01  1.13903732e-02 -4.01569928e-02  2.40997712e-01\n",
      "  -3.36381909e-01 -1.24150816e-01 -1.24150816e-01 -1.47855620e-01\n",
      "  -3.43578978e-01  1.15129407e-04  2.98264820e-03  3.64747706e-03\n",
      "   1.90240163e-03 -2.06934292e-03 -3.04856822e-03  3.62798586e-02\n",
      "  -5.59775658e-02 -3.56187884e-02  2.45220211e-02  1.60741566e-02\n",
      "   4.14745374e-02  7.57539111e-03  1.64627634e-02  1.72769804e-02\n",
      "   1.46964259e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -6.61783266e-02 -2.97736656e-02\n",
      "  -2.96560556e-02 -2.66238803e-02 -1.93740791e-02 -3.92053463e-02\n",
      "  -1.03665950e-03 -2.10044279e-02 -6.66739046e-03 -1.96367422e-02\n",
      "  -3.52578380e-02 -1.40045154e-02 -2.81100801e-02 -1.44705248e-02\n",
      "   1.63710232e-02  1.78504526e-04 -8.52344904e-03 -1.44430158e-02\n",
      "  -5.30990580e-03  1.76057250e-02 -2.39592497e-03  2.47549414e-03\n",
      "  -8.24855891e-03 -6.08741291e-03 -2.58786374e-03 -9.11758234e-03\n",
      "  -8.14839121e-03 -5.77141298e-03 -4.33036556e-03 -4.19668038e-03\n",
      "   2.37682065e-02  3.06520922e-02  1.05267070e-02  9.71696188e-03\n",
      "   7.21154723e-03  1.51942118e-02  7.81231481e-04  5.39059737e-04\n",
      "  -4.31967325e-03 -1.30080226e-02  1.83115824e-01 -7.97967056e-02\n",
      "  -2.34680057e-01 -2.16055969e-01 -1.45394738e-01  1.53340671e-02\n",
      "   4.21883930e-03  4.64411836e-03  4.28387168e-03  3.67351818e-03\n",
      "   9.20565420e-05 -1.10656438e-03  2.88449318e-04  4.80388234e-04\n",
      "   6.55111964e-04  4.71593164e-02  1.19588922e-02  6.47703563e-03\n",
      "   6.49717968e-03  5.35181941e-03  4.90605832e-04  3.66693846e-04\n",
      "   2.44527817e-03 -1.25256872e-04]]\n",
      "[-0.35568391]\n"
     ]
    }
   ],
   "source": [
    "# display coef for logistic regression model\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(solver='lbfgs')\n",
    "# lr.fit(X_tr, y_tr)\n",
    "# predictions = lr.predict(X_tr)\n",
    "# params = np.append(lr.intercept_, lr.coef_)\n",
    "# newX = pd.DataFrame({\"Constant\":np.ones(len(X_tr))}).join(pd.DataFrame(X_tr.reset_index(drop=True)))\n",
    "# MSE = (sum((y_tr-predictions)**2))/(len(newX)-len(newX.columns))\n",
    "\n",
    "\n",
    "# var_b = MSE*(np.linalg.inv(np.dot(newX.T,newX)).diagonal())\n",
    "# sd_b = np.sqrt(var_b)\n",
    "# ts_b = params/ sd_b\n",
    "# print(newX)\n",
    "# p_values =[2*(1-stats.t.cdf(np.abs(i),(len(newX)-1))) for i in ts_b]\n",
    "\n",
    "# sd_b = np.round(sd_b,3)\n",
    "# ts_b = np.round(ts_b,3)\n",
    "# p_values = np.round(p_values,3)\n",
    "# params = np.round(params,4)\n",
    "\n",
    "# myDF3 = pd.DataFrame()\n",
    "# myDF3[\"Coefficients\"],myDF3[\"Standard Errors\"],myDF3[\"t values\"],myDF3[\"Probabilites\"] = [params,sd_b,ts_b,p_values]\n",
    "# print(myDF3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test_1)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_tr)\n",
    "X_tr = ss.transform(X_tr)\n",
    "X_val = ss.transform(X_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of the LogisticRegression classifier on training set: 0.86738\n",
      "Precision on train: 0.92484\n",
      "Recall on train: 0.40936\n",
      "\n",
      "Classification accuracy of the LogisticRegression classifier on val set: 0.86698\n",
      "Precision on val: 0.90892\n",
      "Recall on val: 0.41441\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_tr, y_tr)\n",
    "ca = lr.score(X_tr, y_tr)\n",
    "print('Classification accuracy of the LogisticRegression classifier on training set: {:.5f}'.format(ca))\n",
    "y_pred = lr.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "ca = lr.score(X_val, y_val)\n",
    "y_pred = lr.predict(X_val)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_val, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_val, pos_label=1)\n",
    "print('\\nClassification accuracy of the LogisticRegression classifier on val set: {:.5f}'.format(ca))\n",
    "print('Precision on val: {:.5f}'.format(p))\n",
    "print('Recall on val: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07804281  0.01624625  0.0476366  -0.32152508  0.15397546 -0.32122188\n",
      "  -0.32122188  0.08026875 -0.35737078  0.39725254  0.02732427  0.01451928\n",
      "   0.01081202 -0.07724027 -0.00967198  0.2068572  -0.1009247   0.01828702\n",
      "   0.1217319   0.0851079  -0.99763769  0.29499606  0.40362173  0.32964198\n",
      "   0.29906465  0.          0.          0.          0.          0.\n",
      "  -0.77583769 -0.90383636 -0.98539065 -0.94864671 -0.78942148  0.54392582\n",
      "  -0.06757526 -0.20735805 -0.0384345  -0.36863901 -0.75300566  0.10106284\n",
      "   0.25715888  0.09466896  0.35615553 -0.39946587  0.1513098   0.19408812\n",
      "   0.01196046  0.24716457  0.03733403  0.00615956 -0.05854931 -0.02697436\n",
      "  -0.0108457   0.28697786 -0.30691366  0.04578105 -0.0903777  -0.13997508\n",
      "  -1.14978175 -1.1892526   0.33012709  0.38926754  0.23175321  0.40036788\n",
      "   0.36741606  0.45433813  0.17118616  0.33111041  0.42496547 -0.03022133\n",
      "   0.20422469 -0.38325939 -0.16054445  0.04001925  0.03091578 -0.01390929\n",
      "   0.01289451 -0.05250019 -0.00911924 -0.01525344  0.01817832 -0.01107736\n",
      "   0.03542505  0.11090949  0.05282678  0.05331754 -0.09500166 -0.04996558\n",
      "   3.35604535 -1.23535192 -0.17865402  0.04517771]]\n",
      "[-1.32017176]\n"
     ]
    }
   ],
   "source": [
    "# display coef for logistic regression model\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test_1)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training dataset: 0.9977227782105831\n",
      "Precision on train: 0.99745\n",
      "Recall on train: 0.99182\n",
      "\n",
      "Accuracy score on the val dataset: 0.96656\n",
      "Precision on val: 0.93982\n",
      "Recall on val: 0.90000\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_tr, y_tr)\n",
    "y_pred = rf.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "accuracy_score_train = rf.score(X_tr, y_tr)\n",
    "print('Accuracy score on the training dataset: {}'.format(accuracy_score_train))\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "# test set\n",
    "y_pred = rf.predict(X_val)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_val, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_val, pos_label=1)\n",
    "accuracy_score_val = rf.score(X_val, y_val)\n",
    "print('\\nAccuracy score on the val dataset: {:.5f}'.format(accuracy_score_val))\n",
    "print('Precision on val: {:.5f}'.format(p))\n",
    "print('Recall on val: {:.5f}'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names of the 10 most important features:\n",
      "1. num_joint_success_project\n",
      "2. num_joint_project\n",
      "3. team_age_in_days\n",
      "4. normalized_proj_span\n",
      "5. activity_intensity\n",
      "6. proj_span\n",
      "7. max_contribution_percentage\n",
      "8. num_Push\n",
      "9. num_Push_Q2\n",
      "10. num_Push_Q3\n"
     ]
    }
   ],
   "source": [
    "features = X.columns[:].values.tolist()\n",
    "important_features = rf.feature_importances_\n",
    "feature_index = np.argsort(important_features)[::-1]\n",
    "print('Names of the 10 most important features:')\n",
    "for n in range(10):\n",
    "    print(\"{}. {}\".format(n+1, features[feature_index[n]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_pred=y_pred, y_true=y_test_1)\n",
    "# # retrive the normalized version of cm\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=['unsuccess','success'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_linear = SVC(kernel='linear')\n",
    "# svc_linear.fit(X_tr, y_tr)\n",
    "# ca = svc_linear.score(X_tr, y_tr)\n",
    "# print('Linear SVC classification accuracy on training set: {:.5f}'.format(ca))\n",
    "# ca = svc_linear.score(X_test, y_test)\n",
    "# print('Linear SVC classification accuracy on test set: {:.5f}'.format(ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Radial Basis Function SVC classification accuracy on training set: 0.87889\n",
      "Radial Basis Function SVC classification accuracy on val set: 0.87021\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "svc_rbf = SVC(kernel='rbf')\n",
    "svc_rbf.fit(X_tr, y_tr)\n",
    "ca = svc_rbf.score(X_tr, y_tr)\n",
    "print('\\nRadial Basis Function SVC classification accuracy on training set: {:.5f}'.format(ca))\n",
    "ca = svc_rbf.score(X_val, y_val)\n",
    "print('Radial Basis Function SVC classification accuracy on val set: {:.5f}'.format(ca))\n",
    "\n",
    "# svc_poly = SVC(kernel='poly')\n",
    "# svc_poly.fit(X_tr, y_tr)\n",
    "# ca = svc_poly.score(X_tr, y_tr)\n",
    "# print('\\nPolynomial SVC classification accuracy on training set: {:.5f}'.format(ca))\n",
    "# ca = svc_poly.score(X_test, y_test)\n",
    "# print('Polynomial SVC classification accuracy on test set: {:.5f}'.format(ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on train: 0.98848\n",
      "Recall on train: 0.43530\n",
      "Precision on val: 0.97119\n",
      "Recall on val: 0.40000\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc_rbf.predict(X_tr)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_tr, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_tr, pos_label=1)\n",
    "print('Precision on train: {:.5f}'.format(p))\n",
    "print('Recall on train: {:.5f}'.format(r))\n",
    "\n",
    "y_pred = svc_rbf.predict(X_val)\n",
    "p = precision_score(y_pred=y_pred,y_true=y_val, pos_label=1)\n",
    "r = recall_score(y_pred=y_pred, y_true=y_val, pos_label=1)\n",
    "print('Precision on val: {:.5f}'.format(p))\n",
    "print('Recall on val: {:.5f}'.format(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
